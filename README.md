# Week7-Using LoRA instead of full finetuning
本次作業以[此guideline](https://huggingface.co/docs/transformers/v4.41.3/en/peft)為基礎來實作，並嘗試以兩種不同的config來測試結果

## Result
config1:  
![image](https://github.com/mvclab-ntust-course/course7-llm-milliehsieh/blob/main/1.png)  
  
config2:  
![image](https://github.com/mvclab-ntust-course/course7-llm-milliehsieh/blob/main/2.png)  
